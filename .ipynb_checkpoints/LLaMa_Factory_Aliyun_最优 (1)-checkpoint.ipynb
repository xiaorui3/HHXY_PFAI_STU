{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a60c63-090b-473e-a0df-dfc89c8ba544",
   "metadata": {},
   "source": [
    "1. Install LLaMa-Factory 安装LLaMa-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e92016-d96e-4742-b229-e37fd11bdad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLaMA-Factory'...\n",
      "error: RPC failed; curl 16 Error in the HTTP2 framing layer\n",
      "fatal: expected flush after ref listing\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9381cf-31c0-4dd9-94e3-6d5b34de7ed8",
   "metadata": {},
   "source": [
    "2. Configure Environment 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acac4706-5134-4172-be2d-932648d90756",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xiaorui/LLaMA-Factory\n",
      "/bin/bash: line 1: pip: command not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pip: command not found\n",
      "/bin/bash: line 1: pip: command not found\n",
      "/bin/bash: line 1: pip: command not found\n",
      "/bin/bash: line 1: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory\n",
    "pip install -r requirements.txt\n",
    "pip install transformers_stream_generator bitsandbytes tiktoken auto-gptq optimum autoawq\n",
    "pip install --upgrade tensorflow\n",
    "pip uninstall flash-attn -y\n",
    "pip install vllm==0.4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bd8d6",
   "metadata": {},
   "source": [
    "(Optional) Generate public network link （可选）生成公网链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd355b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/share=False/share=True/' src/train_web.py\n",
    "!sed -i 's/share=False/share=True/' src/web_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11d085f-1e63-4ed7-ad45-d806f08499fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T16:46:59.474645Z",
     "iopub.status.busy": "2024-07-07T16:46:59.474360Z",
     "iopub.status.idle": "2024-07-07T16:47:12.055096Z",
     "shell.execute_reply": "2024-07-07T16:47:12.054199Z",
     "shell.execute_reply.started": "2024-07-07T16:46:59.474624Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Obtaining file:///mnt/workspace/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.41.2 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (4.42.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.16.1)\n",
      "Requirement already satisfied: accelerate>=0.30.1 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.32.1)\n",
      "Requirement already satisfied: peft>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.11.1)\n",
      "Requirement already satisfied: trl>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.9.4)\n",
      "Requirement already satisfied: gradio>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (4.37.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.2.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (1.11.4)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.1.99)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (3.20.3)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.27.0.post1)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.5.3)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.109.0)\n",
      "Requirement already satisfied: sse-starlette in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (2.0.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (3.9.1)\n",
      "Requirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.5.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (1.26.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (3.8.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from llamafactory==0.8.3.dev0) (0.42.1)\n",
      "Collecting rouge-chinese (from llamafactory==0.8.3.dev0)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/03/0f/394cf877be7b903881020ef7217f7dc644dad158d52a9353fcab22e3464d/rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (5.9.7)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.30.1->llamafactory==0.8.3.dev0) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets>=2.16.0->llamafactory==0.8.3.dev0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->llamafactory==0.8.3.dev0) (3.9.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (5.3.0)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.0.2 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (6.4.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.1.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.9.12)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (10.2.0)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.5.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.2.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.0.2->gradio>=4.0.0->llamafactory==0.8.3.dev0) (11.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.8.3.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.8.3.dev0) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->llamafactory==0.8.3.dev0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->llamafactory==0.8.3.dev0) (2.14.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.2->llamafactory==0.8.3.dev0) (0.19.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl>=0.8.6->llamafactory==0.8.3.dev0) (0.7.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->llamafactory==0.8.3.dev0) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->llamafactory==0.8.3.dev0) (0.35.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->llamafactory==0.8.3.dev0) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->llamafactory==0.8.3.dev0) (2.4.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->llamafactory==0.8.3.dev0) (1.3.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from sse-starlette->llamafactory==0.8.3.dev0) (4.2.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (4.21.1)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.12.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->llamafactory==0.8.3.dev0) (4.0.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->llamafactory==0.8.3.dev0) (2.0.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->sse-starlette->llamafactory==0.8.3.dev0) (1.2.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (2.8.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (12.5.82)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (13.7.0)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (0.15)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.8.6->llamafactory==0.8.3.dev0) (1.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.17.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (2.17.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.30.1->llamafactory==0.8.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.3.dev0) (0.1.2)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.8.3.dev0-0.editable-py3-none-any.whl size=20643 sha256=da06f164c3f1edf87809e6989bbbd9c8d87e2d3162267a578f33a7da314808ea\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0piv3051/wheels/5c/79/7e/72c80d84fb58351f0f8d2e48a93b05787aabc61467c934c42c\n",
      "Successfully built llamafactory\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: rouge-chinese, llamafactory\n",
      "Successfully installed llamafactory-0.8.3.dev0 rouge-chinese-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .[metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99385d22-d597-4a3b-a3fa-e4cfbfcfda36",
   "metadata": {},
   "source": [
    "3.Run LLaMa-Factory 运行LLaMa-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e5420-f5b6-4f6c-bb6f-3b0946ad2983",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-07T16:48:28.189829Z",
     "iopub.status.busy": "2024-07-07T16:48:28.189455Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-08 00:48:30.660066: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 00:48:30.672507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 00:48:30.690990: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 00:48:30.691031: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 00:48:30.702052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 00:48:31.590876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "[2024-07-08 00:48:37,476] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "2024-07-08 00:49:29.502851: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 00:49:29.516360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 00:49:29.534206: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 00:49:29.534246: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 00:49:29.544887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 00:49:30.492496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "[2024-07-08 00:49:35,233] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "07/08/2024 00:49:38 - WARNING - llamafactory.hparams.parser - Evaluating model in 4/8-bit mode may cause lower scores.\n",
      "07/08/2024 00:49:38 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None\n",
      "[INFO|tokenization_auto.py:675] 2024-07-08 00:49:38,074 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/llamafactory-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/mnt/workspace/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n",
      "    run_exp()\n",
      "  File \"/mnt/workspace/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 50, in run_exp\n",
      "    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
      "  File \"/mnt/workspace/LLaMA-Factory/src/llamafactory/train/sft/workflow.py\", line 44, in run_sft\n",
      "    tokenizer_module = load_tokenizer(model_args)\n",
      "  File \"/mnt/workspace/LLaMA-Factory/src/llamafactory/model/loader.py\", line 69, in load_tokenizer\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py\", line 846, in from_pretrained\n",
      "    config = AutoConfig.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 965, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py\", line 373, in cached_file\n",
      "    raise EnvironmentError(\n",
      "OSError: /mnt/workspace/dataset does not appear to have a file named config.json. Checkout 'https://huggingface.co//mnt/workspace/dataset/tree/main' for available files.\n",
      "2024-07-08 00:51:02.814661: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 00:51:02.826657: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-08 00:51:02.845012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-08 00:51:02.845053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-08 00:51:02.856011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 00:51:03.750894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "[2024-07-08 00:51:08,223] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "07/08/2024 00:51:10 - WARNING - llamafactory.hparams.parser - Evaluating model in 4/8-bit mode may cause lower scores.\n",
      "07/08/2024 00:51:10 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: None\n",
      "[INFO|tokenization_utils_base.py:2159] 2024-07-08 00:51:10,934 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2159] 2024-07-08 00:51:10,934 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2159] 2024-07-08 00:51:10,934 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2159] 2024-07-08 00:51:10,934 >> loading file tokenizer_config.json\n",
      "07/08/2024 00:51:11 - INFO - llamafactory.data.template - Add pad token: <|endoftext|>\n",
      "07/08/2024 00:51:11 - INFO - llamafactory.data.loader - Loading dataset 特殊字符已经修复的944题.json...\n",
      "Generating train split: 944 examples [00:00, 38963.80 examples/s]\n",
      "Converting format of dataset (num_proc=16): 100%|█| 944/944 [00:00<00:00, 4824.9\n",
      "Running tokenizer on dataset (num_proc=16): 100%|█| 944/944 [00:01<00:00, 783.92\n",
      "input_ids:\n",
      "[7932, 37, 2101, 37, 1265, 441, 248, 531, 51, 28, 273, 531, 51, 29, 19437, 275, 248, 26131, 28, 6078, 8307, 11857, 4354, 271, 248, 531, 51, 30, 273, 531, 51, 31, 19437, 272, 3072, 275, 525, 1034, 24, 20856, 6743, 42, 193, 12340, 19, 1944, 304, 736, 532, 3312, 3173, 495, 275, 248, 2972, 2546, 2045, 317, 37, 390, 7283, 272, 248, 1034, 7281, 6743, 272, 531, 51, 28, 54, 51, 29, 1226, 272, 241, 1623, 272, 248, 10771, 1192, 248, 847, 19437, 273, 241, 13931, 5405, 1192, 248, 19915, 12695, 54195, 25, 341, 37, 390, 531, 51, 28, 273, 531, 51, 29, 19437, 1052, 241, 64090, 34665, 4631, 246, 606, 531, 51, 30, 273, 531, 51, 31, 25, 319, 37, 531, 51, 28, 17056, 204, 30, 304, 2740, 661, 531, 51, 30, 17056, 204, 30, 273, 248, 2483, 246, 1192, 531, 51, 28, 273, 531, 51, 29, 304, 1373, 20601, 15768, 13931, 661, 325, 1192, 531, 51, 30, 273, 531, 51, 31, 25, 361, 37, 4552, 275, 248, 20601, 15768, 12001, 773, 248, 12977, 1192, 248, 847, 17056, 204, 30, 19979, 255, 362, 55105, 272, 531, 51, 28, 54, 51, 29, 1993, 6114, 23, 480, 362, 1104, 272, 531, 51, 30, 54, 51, 31, 25, 399, 37, 390, 531, 51, 28, 273, 531, 51, 29, 19437, 8307, 788, 248, 847, 13220, 204, 28, 32639, 23, 248, 1034, 7281, 2483, 246, 23, 273, 248, 319, 14600, 17056, 7608, 939, 275, 1148, 7281, 25, 378, 37, 390, 2895, 1192, 248, 19915, 12695, 54195, 275, 531, 51, 28, 273, 531, 51, 29, 304, 24442, 8181, 25, 193, 49, 268, 1043, 37]\n",
      "inputs:\n",
      "User: question: How do the KH1 and KH2 domains of the IMP1 protein interact differently compared to the KH3 and KH4 domains in terms of their inter-domain interface?\n",
      "Options(There is only one correct answer out of the six options): A: The differences in the inter domain interface in KH1KH2 result in a change in the angle between the two domains and a shorter distance between the RNA binding grooves. B: The KH1 and KH2 domains form a symmetrical pseudo dimer like KH3 and KH4. C: KH1 alpha 3 is longer than KH3 alpha 3 and the linker between KH1 and KH2 is three amino acids shorter than that between KH3 and KH4. D: Many of the amino acids mediating the contacts between the two alpha 3 helices are conserved in KH1KH2 across species, but are different in KH3KH4. E: The KH1 and KH2 domains interact through the two beta 1 strands, the inter domain linker, and the C terminal alpha helix of each domain. F: The path between the RNA binding grooves of KH1 and KH2 is negatively charged.\n",
      "Falcon:\n",
      "[INFO|configuration_utils.py:731] 2024-07-08 00:51:13,704 >> loading configuration file /mnt/workspace/dataset/falcon-7b/config.json\n",
      "[INFO|configuration_utils.py:731] 2024-07-08 00:51:13,710 >> loading configuration file /mnt/workspace/dataset/falcon-7b/config.json\n",
      "[INFO|configuration_utils.py:800] 2024-07-08 00:51:13,711 >> Model config FalconConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/dataset/falcon-7b/\",\n",
      "  \"alibi\": false,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"FalconForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_falcon.FalconConfig\",\n",
      "    \"AutoModel\": \"modeling_falcon.FalconModel\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_falcon.FalconForCausalLM\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modeling_falcon.FalconForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_falcon.FalconForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modeling_falcon.FalconForTokenClassification\"\n",
      "  },\n",
      "  \"bias\": false,\n",
      "  \"bos_token_id\": 11,\n",
      "  \"eos_token_id\": 11,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4544,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"falcon\",\n",
      "  \"multi_query\": true,\n",
      "  \"new_decoder_architecture\": false,\n",
      "  \"num_attention_heads\": 71,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_kv_heads\": 71,\n",
      "  \"parallel_attn\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "07/08/2024 00:51:13 - INFO - llamafactory.model.model_utils.quantization - Quantizing model to 4 bit with bitsandbytes.\n",
      "07/08/2024 00:51:13 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
      "[INFO|modeling_utils.py:3553] 2024-07-08 00:51:13,771 >> loading weights file /mnt/workspace/dataset/falcon-7b/pytorch_model.bin.index.json\n",
      "[INFO|modeling_utils.py:1531] 2024-07-08 00:51:13,771 >> Instantiating FalconForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1000] 2024-07-08 00:51:13,772 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 11,\n",
      "  \"eos_token_id\": 11\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:18<00:00,  9.40s/it]\n",
      "[INFO|modeling_utils.py:4364] 2024-07-08 00:51:32,817 >> All model checkpoint weights were used when initializing FalconForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4372] 2024-07-08 00:51:32,818 >> All the weights of FalconForCausalLM were initialized from the model checkpoint at /mnt/workspace/dataset/falcon-7b/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use FalconForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:953] 2024-07-08 00:51:32,820 >> loading configuration file /mnt/workspace/dataset/falcon-7b/generation_config.json\n",
      "[INFO|configuration_utils.py:1000] 2024-07-08 00:51:32,821 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 11,\n",
      "  \"eos_token_id\": 11\n",
      "}\n",
      "\n",
      "07/08/2024 00:51:32 - INFO - llamafactory.model.model_utils.attention - Using vanilla attention implementation.\n",
      "07/08/2024 00:51:32 - INFO - llamafactory.model.loader - all params: 6,921,720,704\n",
      "[INFO|trainer.py:3788] 2024-07-08 00:51:33,059 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:3790] 2024-07-08 00:51:33,059 >>   Num examples = 944\n",
      "[INFO|trainer.py:3793] 2024-07-08 00:51:33,059 >>   Batch size = 2\n",
      "  0%|▏                                       | 2/472 [02:47<10:54:35, 83.57s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 USE_MODELSCOPE_HUB=1 python src/webui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "share": {
   "datetime": "2024-01-26T18:27:52.135Z",
   "image": {
    "name": "modelscope:1.11.0-pytorch2.1.2tensorflow2.14.0-gpu-py310-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-shanghai.cr.aliyuncs.com/pai/modelscope:1.11.0-pytorch2.1.2tensorflow2.14.0-gpu-py310-cu121-ubuntu22.04"
   },
   "instance": "dsw-7ee0403fc8f6819a",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1947990434175216"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
